import streamlit as st
import pdfplumber
import pandas as pd
import io
import re
from datetime import datetime

# --- 1. å®šç¾©æ¬„ä½èˆ‡é—œéµå­— ---
KEYWORD_MAP = {
    "Pb": ["Lead", "é‰›", "Pb"],
    "Cd": ["Cadmium", "é˜", "Cd"],
    "Hg": ["Mercury", "æ±", "Hg"],
    "Cr6+": ["Hexavalent Chromium", "å…­åƒ¹é‰»", "Cr(VI)", "Chromium VI"],
    "PBB": ["Sum of PBBs", "å¤šæº´è¯è‹¯ç¸½å’Œ", "PBBs", "Polybrominated Biphenyls"],
    "PBDE": ["Sum of PBDEs", "å¤šæº´è¯è‹¯é†šç¸½å’Œ", "PBDEs", "Polybrominated Diphenyl Ethers"],
    "DEHP": ["DEHP", "Di(2-ethylhexyl) phthalate", "Bis(2-ethylhexyl) phthalate"],
    "BBP": ["BBP", "Butyl benzyl phthalate"],
    "DBP": ["DBP", "Dibutyl phthalate"],
    "DIBP": ["DIBP", "Diisobutyl phthalate"],
    "PFOS": ["PFOS", "Perfluorooctane sulfonates", "Perfluorooctane sulfonate"],
    "F": ["Fluorine", "æ°Ÿ"],
    "CL": ["Chlorine", "æ°¯"],
    "BR": ["Bromine", "æº´"],
    "I": ["Iodine", "ç¢˜"]
}

OUTPUT_COLUMNS = [
    "Pb", "Cd", "Hg", "Cr6+", "PBB", "PBDE", 
    "DEHP", "BBP", "DBP", "DIBP", 
    "PFOS", "F", "CL", "BR", "I", 
    "å–®ä½", "æ—¥æœŸ", "æª”æ¡ˆåç¨±"
]

# --- 2. è¼”åŠ©åŠŸèƒ½ ---

def clean_text(text):
    """æ¸…ç†æ–‡å­—ï¼šç§»é™¤æ›è¡Œã€å¤šé¤˜ç©ºç™½"""
    if not text: return ""
    return str(text).replace('\n', ' ').strip()

def extract_date_from_text(text):
    """å…¨æ–¹ä½æ—¥æœŸæŠ“å–"""
    text = clean_text(text)
    # æ¨¡å¼ 1: 06-Jan-2025
    match1 = re.search(r"([0-9]{2}-[a-zA-Z]{3}-[0-9]{4})", text)
    if match1:
        try: return datetime.strptime(match1.group(1), "%d-%b-%Y")
        except: pass
    # æ¨¡å¼ 2: 2025/01/06, 2025.01.06, 2025-01-06
    match2 = re.search(r"([0-9]{4})[/\.-]([0-9]{1,2})[/\.-]([0-9]{1,2})", text)
    if match2:
        try: return datetime(int(match2.group(1)), int(match2.group(2)), int(match2.group(3)))
        except: pass
    return None

def parse_value_priority(value_str):
    """æ±ºå®šæ•¸å€¼å„ªå…ˆç´š & æ¸…æ´—å–®ä½"""
    val = clean_text(value_str).replace("mg/kg", "").replace("ppm", "").replace("%", "").replace("Âµg/cmÂ²", "").strip()
    
    if not val: return (0, 0, "")
    val_lower = val.lower()

    if "n.d." in val_lower or "nd" == val_lower or "<" in val_lower: return (1, 0, "n.d.")
    if "negative" in val_lower or "é™°æ€§" in val_lower: return (2, 0, "Negative")
    
    # æŠ“å–æ•¸å­—
    num_match = re.search(r"([\d\.]+)", val)
    if num_match:
        try:
            number = float(num_match.group(1))
            return (3, number, val)
        except: pass
            
    return (0, 0, val)

# --- 3. æ ¸å¿ƒï¼šå‹•æ…‹æ¬„ä½è­˜åˆ¥ ---

def identify_columns(header_row):
    """
    åˆ†æè¡¨é ­åˆ—ï¼Œæ‰¾å‡º 'Result' å’Œ 'Unit' åˆ†åˆ¥åœ¨ç¬¬å¹¾æ¬„
    å›å‚³: (item_idx, result_idx, unit_idx)
    """
    item_idx = -1
    result_idx = -1
    unit_idx = -1
    
    for i, cell in enumerate(header_row):
        txt = clean_text(cell).lower()
        
        # æ‰¾æ¸¬é …æ¬„ (é€šå¸¸æ˜¯ Item, Test Item)
        if "test item" in txt or "tested item" in txt or "æ¸¬è©¦é …ç›®" in txt:
            item_idx = i
        
        # æ‰¾çµæœæ¬„ (Result, çµæœ, No.1, 004)
        if "result" in txt or "çµæœ" in txt:
            result_idx = i
            
        # æ‰¾å–®ä½æ¬„ (Unit, å–®ä½)
        if "unit" in txt or "å–®ä½" in txt:
            unit_idx = i
            
    return item_idx, result_idx, unit_idx

def process_files(files):
    data_pool = {key: [] for key in KEYWORD_MAP.keys()}
    all_dates = []
    
    progress_bar = st.progress(0)
    
    for i, file in enumerate(files):
        filename = file.name
        current_date = None
        
        try:
            with pdfplumber.open(file) as pdf:
                # 1. æŠ“æ—¥æœŸ
                first_page_text = pdf.pages[0].extract_text()
                current_date = extract_date_from_text(first_page_text)
                if current_date:
                    all_dates.append((current_date, filename))

                # 2. æŠ“è¡¨æ ¼
                for page in pdf.pages:
                    tables = page.extract_tables()
                    for table in tables:
                        if not table or len(table) < 2: continue
                        
                        # A. å…ˆå˜—è©¦è®€å–ç¬¬ä¸€åˆ—ç•¶ä½œè¡¨é ­ï¼Œå®šä½æ¬„ä½ç´¢å¼•
                        header_row = table[0]
                        item_idx, result_idx, unit_idx = identify_columns(header_row)
                        
                        # B. å¦‚æœè¡¨é ­æ²’æŠ“åˆ° Resultï¼Œå˜—è©¦ç”¨å‚™ç”¨é‚è¼¯ (SGS ç¶“å…¸ç‰ˆé€šå¸¸ Result åœ¨å€’æ•¸ç¬¬2æˆ–3æ¬„)
                        # ä½†å› ç‚ºæ ¼å¼å¤ªå¤šè®Šï¼Œå¦‚æœæ²’æŠ“åˆ°ï¼Œæˆ‘å€‘æœƒåœ¨æ¯ä¸€åˆ—å‹•æ…‹åˆ¤æ–·
                        
                        # C. éæ­·æ¯ä¸€åˆ—æ•¸æ“š
                        for row_idx, row in enumerate(table):
                            # è·³éè¡¨é ­åˆ—
                            if row_idx == 0: continue
                            
                            clean_row = [clean_text(cell) for cell in row]
                            
                            # ç¢ºä¿é€™ä¸€åˆ—æœ‰è³‡æ–™
                            if not any(clean_row): continue
                            
                            # 1. ç¢ºå®šæ¸¬é …åç¨±
                            # å¦‚æœæœ‰æŠ“åˆ° item_idx å°±ç”¨å®ƒï¼Œå¦å‰‡é è¨­ç”¨ç¬¬0æ¬„
                            target_item_col = item_idx if item_idx != -1 else 0
                            if target_item_col >= len(clean_row): continue
                            item_name = clean_row[target_item_col]
                            
                            # é˜²å‘†ï¼šå¦‚æœé€™ä¸€æ¬„æ˜¯ "Test Item" æ¨™é¡Œï¼Œè·³é
                            if "test item" in item_name.lower() or "æ¸¬è©¦é …ç›®" in item_name: continue

                            # 2. ç¢ºå®šçµæœèˆ‡å–®ä½
                            result = ""
                            unit = ""
                            
                            # ç­–ç•¥ A: æ ¹æ“šè¡¨é ­æŠ“åˆ°çš„ç´¢å¼•
                            if result_idx != -1 and result_idx < len(clean_row):
                                result = clean_row[result_idx]
                            
                            if unit_idx != -1 and unit_idx < len(clean_row):
                                unit = clean_row[unit_idx]
                                
                            # ç­–ç•¥ B (å‚™æ´): å¦‚æœæ²’æŠ“åˆ°è¡¨é ­ï¼Œç”¨ã€Œå…§å®¹ç‰¹å¾µã€çŒœ
                            if not result:
                                # æ‰¾çœ‹èµ·ä¾†åƒçµæœçš„æ ¼å­ (åŒ…å« n.d., Negative, æˆ–è€…æ•¸å­—)
                                # å€’è‘—æ‰¾å›ä¾†é€šå¸¸æ¯”è¼ƒæº– (Result é€šå¸¸åœ¨å³é‚Š)
                                for cell in reversed(clean_row):
                                    c_lower = cell.lower()
                                    if "n.d." in c_lower or "negative" in c_lower or re.search(r"^\d+(\.\d+)?$", cell):
                                        result = cell
                                        break
                            
                            if not unit:
                                # æ‰¾çœ‹èµ·ä¾†åƒå–®ä½çš„æ ¼å­
                                for cell in clean_row:
                                    if "mg/kg" in cell or "ppm" in cell:
                                        unit = cell
                                        break
                            
                            # å¦‚æœé‚„æ˜¯æ²’æŠ“åˆ°å–®ä½ï¼Œä½†çµæœæ¬„ä½è£¡é¢æœ‰å–®ä½ (ä¾‹å¦‚ "8 mg/kg")
                            if result and not unit:
                                if "mg/kg" in result: unit = "mg/kg"
                                elif "ppm" in result: unit = "ppm"

                            # 3. åŒ¹é…é—œéµå­—ä¸¦å­˜æª”
                            for target_key, keywords in KEYWORD_MAP.items():
                                for kw in keywords:
                                    # ä½¿ç”¨è¼ƒåš´æ ¼çš„æ¯”å°ï¼Œé¿å… PBB æŠ“åˆ° PBBs-related
                                    if kw.lower() in item_name.lower():
                                        priority = parse_value_priority(result)
                                        data_pool[target_key].append({
                                            "priority": priority,
                                            "filename": filename,
                                            "date": current_date,
                                            "unit": unit
                                        })
                                        break 
                                    
        except Exception as e:
            st.warning(f"æª”æ¡ˆ {filename} è§£æç•°å¸¸: {e}")

        progress_bar.progress((i + 1) / len(files))

    # --- 4. èšåˆ ---
    final_row = {}
    max_val_filename = "" 
    global_max_score = -1
    default_unit = ""

    for key in KEYWORD_MAP.keys():
        candidates = data_pool[key]
        if not candidates:
            final_row[key] = "" 
            continue
            
        best_record = sorted(candidates, key=lambda x: (x['priority'][0], x['priority'][1]), reverse=True)[0]
        final_row[key] = best_record['priority'][2]
        
        if best_record['priority'][0] == 3 and not default_unit:
            default_unit = best_record['unit']
            
        if best_record['priority'][0] > global_max_score:
            global_max_score = best_record['priority'][0]
            max_val_filename = best_record['filename']
        elif best_record['priority'][0] == 3 and global_max_score == 3:
             max_val_filename = best_record['filename']

    final_date_str = ""
    latest_file_name_by_date = ""
    if all_dates:
        latest_date_record = sorted(all_dates, key=lambda x: x[0], reverse=True)[0]
        final_date_str = latest_date_record[0].strftime("%Y/%m/%d")
        latest_file_name_by_date = latest_date_record[1]
    
    final_row["å–®ä½"] = default_unit if default_unit else "mg/kg"
    final_row["æ—¥æœŸ"] = final_date_str
    
    if global_max_score == 3: 
        final_row["æª”æ¡ˆåç¨±"] = max_val_filename
    else:
        final_row["æª”æ¡ˆåç¨±"] = latest_file_name_by_date if latest_file_name_by_date else (files[0].name if files else "")

    return [final_row]

# --- ä»‹é¢ ---
st.set_page_config(page_title="SGS å ±å‘Šèšåˆå·¥å…· v4.0", layout="wide")
st.title("ğŸ“„ è¬ç”¨å‹æª¢æ¸¬å ±å‘Šèšåˆå·¥å…· (SGS/Intertek/ALS é€šç”¨ç‰ˆ)")
st.info("ğŸ’¡ v4.0 æ›´æ–°ï¼šæ”¯æ´å¤šç¨®ä¸åŒå» å•†çš„å ±å‘Šæ ¼å¼ (è‡ªå‹•è­˜åˆ¥ Result èˆ‡ Unit ä½ç½®)")

uploaded_files = st.file_uploader("è«‹ä¸€æ¬¡é¸å–æ‰€æœ‰ PDF æª”æ¡ˆ", type="pdf", accept_multiple_files=True)

if uploaded_files:
    if st.button("ğŸ”„ é‡æ–°åŸ·è¡Œ"): st.rerun()

    try:
        result_data = process_files(uploaded_files)
        df = pd.DataFrame(result_data)
        
        for col in OUTPUT_COLUMNS:
            if col not in df.columns: df[col] = ""
        df = df[OUTPUT_COLUMNS]

        st.success("âœ… è™•ç†å®Œæˆï¼")
        st.dataframe(df)

        output = io.BytesIO()
        with pd.ExcelWriter(output, engine='openpyxl') as writer:
            df.to_excel(writer, index=False, sheet_name='Summary')
        
        st.download_button("ğŸ“¥ ä¸‹è¼‰ Excel", data=output.getvalue(), file_name="Report_Summary_v4.xlsx", mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet")
        
    except Exception as e:
        st.error(f"ç³»çµ±éŒ¯èª¤: {e}")
