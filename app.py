import streamlit as st
import pdfplumber
import pandas as pd
import io
import re
from datetime import datetime

# --- 1. å®šç¾©æ¬„ä½èˆ‡é—œéµå­—å°ç…§è¡¨ ---
KEYWORD_MAP = {
    "Pb": ["Lead", "é‰›", "Pb"],
    "Cd": ["Cadmium", "é˜", "Cd"],
    "Hg": ["Mercury", "æ±", "Hg"],
    "Cr6+": ["Hexavalent Chromium", "å…­åƒ¹é‰»", "Cr(VI)"],
    # PBB/PBDE é—œéµå­—æ”¾å¯¬ï¼Œç¢ºä¿èƒ½æŠ“åˆ° "Sum of PBBs"
    "PBB": ["Sum of PBBs", "å¤šæº´è¯è‹¯ç¸½å’Œ", "PBBs"],
    "PBDE": ["Sum of PBDEs", "å¤šæº´è¯è‹¯é†šç¸½å’Œ", "PBDEs"],
    "DEHP": ["DEHP", "Di(2-ethylhexyl) phthalate"],
    "BBP": ["BBP", "Butyl benzyl phthalate"],
    "DBP": ["DBP", "Dibutyl phthalate"],
    "DIBP": ["DIBP", "Diisobutyl phthalate"],
    "PFOS": ["PFOS", "Perfluorooctane sulfonates"],
    "F": ["Fluorine", "æ°Ÿ"],
    "CL": ["Chlorine", "æ°¯"],
    "BR": ["Bromine", "æº´"],
    "I": ["Iodine", "ç¢˜"]
}

OUTPUT_COLUMNS = [
    "Pb", "Cd", "Hg", "Cr6+", "PBB", "PBDE", 
    "DEHP", "BBP", "DBP", "DIBP", 
    "PFOS", "F", "CL", "BR", "I", 
    "å–®ä½", "æ—¥æœŸ", "æª”æ¡ˆåç¨±"
]

# --- 2. è¼”åŠ©åŠŸèƒ½ ---

def extract_date_from_text(text):
    """
    å…¨æ–¹ä½æ—¥æœŸæŠ“å–ï¼šæ”¯æ´ Jan-01-2025, 2025/01/01, 2025.01.01
    """
    text = text.replace('\n', ' ') # ç§»é™¤æ›è¡Œä»¥å…å¹²æ“¾ regex
    
    # æ¨¡å¼ 1: 06-Jan-2025 (SGS å¸¸ç”¨)
    match1 = re.search(r"([0-9]{2}-[a-zA-Z]{3}-[0-9]{4})", text)
    if match1:
        try:
            return datetime.strptime(match1.group(1), "%d-%b-%Y")
        except: pass

    # æ¨¡å¼ 2: 2025/01/06 or 2025.01.06 (å°ç£å¸¸ç”¨)
    match2 = re.search(r"([0-9]{4})[/\.]([0-9]{1,2})[/\.]([0-9]{1,2})", text)
    if match2:
        try:
            # å˜—è©¦å»ºç«‹æ—¥æœŸç‰©ä»¶
            return datetime(int(match2.group(1)), int(match2.group(2)), int(match2.group(3)))
        except: pass
        
    return None

def parse_value_priority(value_str):
    """æ±ºå®šæ•¸å€¼å„ªå…ˆç´š & æ¸…æ´—å–®ä½"""
    val = str(value_str).replace("mg/kg", "").replace("ppm", "").replace("%", "").strip()
    
    if not val: return (0, 0, "")
    val_lower = val.lower()

    if "n.d." in val_lower or "nd" == val_lower: return (1, 0, "n.d.")
    if "negative" in val_lower or "é™°æ€§" in val_lower: return (2, 0, "Negative")
    
    # æŠ“å–æ•¸å­— (è™•ç† <5, >100 ç­‰ç¬¦è™Ÿ)
    num_match = re.search(r"([\d\.]+)", val)
    if num_match:
        try:
            number = float(num_match.group(1))
            return (3, number, val)
        except: pass
            
    return (0, 0, val)

def smart_find_result(row):
    """
    â˜…æ ¸å¿ƒå‡ç´šï¼šæ™ºæ…§å°‹æ‰¾çµæœèˆ‡å–®ä½æ¬„ä½
    å›å‚³: (Result_Value, Unit_Text)
    """
    unit_idx = -1
    
    # 1. å…ˆæ‰¾å–®ä½åœ¨å“ªä¸€æ ¼ (å®šä½é»)
    for i, cell in enumerate(row):
        cell_text = str(cell).lower()
        if "mg/kg" in cell_text or "ppm" in cell_text or "%" in cell_text:
            unit_idx = i
            break
    
    found_unit = row[unit_idx] if unit_idx != -1 else ""
    found_result = ""

    # 2. æ ¹æ“šå–®ä½ä½ç½®æ¨ç®—çµæœ
    if unit_idx != -1:
        # æ ¹æ“š SGS æ…£ä¾‹ï¼šå–®ä½(Unit) -> MDL -> çµæœ(Result)
        # æ‰€ä»¥çµæœé€šå¸¸åœ¨ å–®ä½ + 2
        result_idx = unit_idx + 2
        if result_idx < len(row):
            found_result = row[result_idx]
        else:
            # å¦‚æœçˆ†å‡ºç¯„åœï¼Œè©¦è©¦çœ‹ +1 (æœ‰æ™‚å€™æ²’æœ‰ MDL æ¬„ä½)
            if unit_idx + 1 < len(row):
                found_result = row[unit_idx + 1]
    else:
        # 3. å¦‚æœæ‰¾ä¸åˆ°å–®ä½ (ä¾‹å¦‚ PBB Sum æ¬„ä½å¯èƒ½æ²’å¯«å–®ä½)ï¼Œæ”¹æ‰¾é—œéµå­— "n.d."
        for cell in row:
            txt = str(cell).strip()
            if "n.d." in txt.lower() or "negative" in txt.lower():
                found_result = txt
                break
                
    return found_result, found_unit

# --- 3. ä¸»æµç¨‹ ---

def process_files(files):
    data_pool = {key: [] for key in KEYWORD_MAP.keys()}
    all_dates = []
    
    progress_bar = st.progress(0)
    
    for i, file in enumerate(files):
        filename = file.name
        current_date = None
        
        try:
            with pdfplumber.open(file) as pdf:
                # æŠ“æ—¥æœŸ
                first_page_text = pdf.pages[0].extract_text()
                current_date = extract_date_from_text(first_page_text)
                if current_date:
                    all_dates.append((current_date, filename))

                # æŠ“è¡¨æ ¼
                for page in pdf.pages:
                    tables = page.extract_tables()
                    for table in tables:
                        for row in table:
                            clean_row = [str(cell).replace('\n', ' ').strip() if cell else "" for cell in row]
                            
                            # åŸºæœ¬éæ¿¾
                            if len(clean_row) >= 3:
                                item_name = clean_row[0]
                                
                                # è·³éæ¨™é¡Œåˆ—
                                if "æ¸¬è©¦é …ç›®" in item_name or "Test Items" in item_name:
                                    continue

                                for target_key, keywords in KEYWORD_MAP.items():
                                    for kw in keywords:
                                        if kw in item_name:
                                            # â˜… ä½¿ç”¨æ™ºæ…§å®šä½æ‰¾çµæœ
                                            result, unit = smart_find_result(clean_row)
                                            
                                            # è‹¥ result ç‚ºç©ºï¼Œå¯èƒ½æ˜¯æ²’æŠ“å°ï¼Œä¿ç•™å½ˆæ€§
                                            if not result and len(clean_row) > 4:
                                                # æœ€å¾Œä¸€æï¼šæœ‰äº›æ ¼å¼ Result åœ¨æœ€å¾Œä¸€æ ¼ (index -1) æˆ–æ˜¯ å€’æ•¸ç¬¬äºŒæ ¼ (index -2)
                                                # å¦‚æœ clean_row[4] çœ‹èµ·ä¾†åƒçµæœ...
                                                pass 

                                            priority = parse_value_priority(result)
                                            
                                            # å­˜å…¥è³‡æ–™
                                            data_pool[target_key].append({
                                                "priority": priority,
                                                "filename": filename,
                                                "date": current_date,
                                                "unit": unit
                                            })
                                            break 
        except Exception as e:
            st.warning(f"æª”æ¡ˆ {filename} è®€å–éƒ¨åˆ†å¤±æ•—: {e}")

        progress_bar.progress((i + 1) / len(files))

    # --- èšåˆ ---
    final_row = {}
    max_val_filename = "" 
    global_max_score = -1
    default_unit = ""

    for key in KEYWORD_MAP.keys():
        candidates = data_pool[key]
        if not candidates:
            final_row[key] = "" 
            continue
            
        best_record = sorted(candidates, key=lambda x: (x['priority'][0], x['priority'][1]), reverse=True)[0]
        final_row[key] = best_record['priority'][2]
        
        if best_record['priority'][0] == 3 and not default_unit:
            default_unit = best_record['unit']
            
        if best_record['priority'][0] > global_max_score:
            global_max_score = best_record['priority'][0]
            max_val_filename = best_record['filename']
        elif best_record['priority'][0] == 3 and global_max_score == 3:
             max_val_filename = best_record['filename']

    # æ—¥æœŸè™•ç†
    final_date_str = ""
    latest_file_name_by_date = ""
    if all_dates:
        latest_date_record = sorted(all_dates, key=lambda x: x[0], reverse=True)[0]
        final_date_str = latest_date_record[0].strftime("%Y/%m/%d") # çµ±ä¸€è½‰ç‚º 2025/01/01 æ ¼å¼
        latest_file_name_by_date = latest_date_record[1]
    
    final_row["å–®ä½"] = default_unit if default_unit else "mg/kg"
    final_row["æ—¥æœŸ"] = final_date_str
    
    if global_max_score == 3: 
        final_row["æª”æ¡ˆåç¨±"] = max_val_filename
    else:
        final_row["æª”æ¡ˆåç¨±"] = latest_file_name_by_date if latest_file_name_by_date else (files[0].name if files else "")

    return [final_row]

# --- ä»‹é¢ ---
st.set_page_config(page_title="SGS å ±å‘Šèšåˆå·¥å…· v3.0", layout="wide")
st.title("ğŸ“„ SGS æª¢æ¸¬å ±å‘Šæ‰¹æ¬¡èšåˆå·¥å…· (æ™ºæ…§ä¿®æ­£ç‰ˆ)")
st.info("ğŸ’¡ æ­¤ç‰ˆæœ¬å·²ä¿®å¾©ï¼šå–®ä½éŒ¯ç½®ã€æ—¥æœŸæŠ“å–ã€æ•¸å€¼èˆ‡MDLæ··æ·†çš„å•é¡Œã€‚")

uploaded_files = st.file_uploader("è«‹ä¸€æ¬¡é¸å–æ‰€æœ‰ PDF æª”æ¡ˆ", type="pdf", accept_multiple_files=True)

if uploaded_files:
    if st.button("ğŸ”„ é‡æ–°åŸ·è¡Œåˆ†æ"):
        st.rerun()

    try:
        result_data = process_files(uploaded_files)
        df = pd.DataFrame(result_data)
        
        for col in OUTPUT_COLUMNS:
            if col not in df.columns: df[col] = ""
        df = df[OUTPUT_COLUMNS]

        st.success("âœ… è™•ç†å®Œæˆï¼")
        st.dataframe(df)

        output = io.BytesIO()
        with pd.ExcelWriter(output, engine='openpyxl') as writer:
            df.to_excel(writer, index=False, sheet_name='Summary')
        
        st.download_button("ğŸ“¥ ä¸‹è¼‰ Excel", data=output.getvalue(), file_name="SGS_Summary_v3.xlsx", mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet")
        
    except Exception as e:
        st.error(f"ç™¼ç”ŸéŒ¯èª¤: {e}")
